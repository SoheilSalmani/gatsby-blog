---
title: Hypermodern Python
resourceId: https://cjolowicz.github.io/posts/hypermodern-python-01-setup/
stoppedAt: Managing virtual environments with Poetry
---

## Setup

### Setting up a GitHub repository

Create a repository, and populate it with `README.md` and `LICENSE` (MIT
license) files.

### Installing Python with pyenv

Install Python releases through pyenv:

```shell
pyenv install 3.8.2
pyenv install 3.7.5
```

Make your fresh Python installations available inside the repository:

```shell
pyenv local 3.8.2 3.7.5
```

Python 3.8.2 is the default version and can be invoked as `python`, but both
versions are accessible as `python3.7` and `python3.8`, respectively.

```shell
python --version
python3.8 --version
python3.7 --version
```

### Setting up a Python project using Poetry

Poetry is a tool to manage Python packaging and dependencies. Its ease of use
and support for modern workflows make it the ideal successor to the venerable
setuptools.

Install Poetry and source `~/.poetry/env` in your current shell.

Initialize your Python project:

```shell
poetry init --no-interaction
```

This command will create a `pyproject.toml` file, the new Python package
configuration file specified in PEP 517 and 518. It's a declarative file in TOML
syntax, containing the entire package configuration.

Add some metadata to the package:

```toml fp=pyproject.toml
[tool.poetry]
...
description = "The hypermodern Python project"
license = "MIT"
readme = "README.md"
homepage = "https://github.com/<your-username>/hypermodern-python"
repository = "https://github.com/<your-username>/hypermodern-python"
keywords = ["hypermodern"]
```

Poetry added a dependency on Python 3.8, because this is the Python version you
ran it in. Support the previous release as well by changing this to Python 3.7:

```toml fp=pyproject.toml hl=2
[tool.poetry.dependencies]
python = "^3.7"
```

The caret (`^`) in front of the version number means “up to the next major
release”. In other words, you are promising that your package won’t break when
users upgrade to Python 3.8 or 3.9, but you’re giving no guarantees for its use
with a future Python 4.0.

### Creating a package in src layout

```tree
.
├── pyproject.toml
└── src
    └── hypermodern_python
        └── __init__.py
```

```python nu fp=src/hypermodern_python/__init__.py
__version__ = "0.1.0"
```

Use snake case for the package name `hypermodern_python`, as opposed to the
kebab case used for the repository name `hypermodern-python`.

### Managing virtual environments with Poetry

Poetry manages virtual environments for your projects.

Install the skeleton package:

```shell
poetry install
```

Poetry has now created a virtual environment dedicated to your project, and
installed your initial package into it. It has also created a so-called _lock_
file, named `poetry.lock`.

Run a Python session inside thew new virtual environment:

```shell
poetry run python
```

```python
>>> import hypermodern_python
>>> hypermodern_python.__version__
```

### Managing dependencies with Poetry

The `click` package allows you to create beautiful command-line interfaces in a
composable way with as little code as necessary.

```shell
poetry add click
```

Several things are happening here:

- The package is downloaded and installed into the virtual environment.
- The installed version is registered in the lock file `poetry.lock`.
- A more general version constraint is added to `pyproject.toml`.

Upgrading the dependency to a new minor or patch release:

```shell
poetry update click
```

To upgrade to a new major release, you need to update the version constraint
explicitly.

```shell
poetry add click^7.0
```

### Command-line interfaces with click

```python nu fp=src/hypermodern_python/console.py
import click

from . import __version__

@click.command()
@click.version_option(version=__version__)
def main():
    """The hypermodern Python project."""
    click.echo("Hello, world!")
```

The `console` module defines a minimal command-line application, supporting
`--help` and `--version` options.

Register the script in `pyproject.toml`.

```toml fp=pyproject.toml
[tool.poetry.scripts]
hypermodern-python = "hypermodern_python.console:main"
```

Finally, install the package into the virtual environment:

```shell
poetry install
```

Run the script:

```shell
poetry run hypermodern-python
```

You can also pass options to your script:

```shell
poetry run hypermodern-python --help
```

### Example: Consuming a REST API with requests

Install the `requests` package, the _de facto_ standard for making HTTP requests
in Python:

```shell
poetry add requests
```

```python nu fp=src/hypermodern_python/console.py
import textwrap

import click
import requests

from . import __version__

API_URL = "https://en.wikipedia.org/api/rest_v1/page/random/summary"

@click.command()
@click.version_option(version=__version__)
def main():
    """The hypermodern Python project."""
    with requests.get(API_URL) as response:
        response.raise_for_status()
        data = response.json()

    title = data["title"]
    extract = data["extract"]

    click.secho(title, fg="green")
    click.echo(textwrap.fill(extract))
```

The `textwrap` module from the standard library allows you to wrap lines when
printing text to the console.

Blank lines serve to group imports as recommended in PEP 8 (standard
library–third party packages–local imports).

The `API_URL` constant points to the REST API of the English Wikipedia, or more
specifically, its `/page/random/summary` endpoint, which returns the summary of
a random Wikipedia article.

The `with` statement ensures that the HTTP connection is closed at the end of
the block. Before looking at the response body, we check the HTTP status code
and raise an exception if it signals an error.

Finally, we print the title and extract to the console, using the `click.echo`
and `click.secho` functions. The latter function allows you to specify the
foreground color using the `fg` keyword attribute. The `textwrap.fill` function
wraps the text in extract so that every line is at most 70 characters long.

Feel free to play around with this a little. Here are some things you might want
to try:

- Display a friendly error message when the API is not reachable.
- Add an option to select the Wikipedia edition for another language.
- If you feel adventurous: auto-detect the user’s preferred language edition,
  using locale.

## Testing

### Unit testing with pytest

Unit tests, as the name says, verify the functionality of a _unit of code_, such
as a single function or class. While the unittest framework is part of the
Python standard library, pytest has become somewhat of a _de facto_ standard.

Add `pytest` as a development dependency:

```shell
poetry add --dev pytest
```

Organize tests in a separate file hierarchy next to `src`, named `tests`:

```tree
.
├── src
└── tests
    ├── __init__.py
    └── test_console.py
```

The file `__init__.py` is empty and serves to declare the test suite as a
package. While this is not strictly necessary, it allows your test suite to
mirror the source layout of the package under test, even when modules in
different parts of the source tree have the same name. Furthermore, it gives you
the option to import modules from within your tests package.

```python nu fp=tests/test_console.py
import click.testing

from hypermodern_python import console

@pytest.fixture
def runner():
    return click.testing.CliRunner()

def test_main_succeeds(runner):
    result = runner.invoke(console.main)
    assert result.exit_code == 0
```

```shell
poetry run pytest
```

### Code coverage with Coverage.py

_Code coverage_ is a measure of the degree to which the source code of your
program is executed while running its test suite. The code coverage of Python
programs can be determined using a tool called Coverage.py. Install it with the
`pytest-cov` plugin, which integrates Coverage.py with `pytest`:

```shell
poetry add --dev coverage[toml] pytest-cov
```

You can configure Coverage.py using the `pyproject.toml` configuration file,
provided it was installed with the `toml` extra. Update this file to inform the
tool about your package name and source tree layout. The configuration also
enables branch analysis and the display of line numbers for missing coverage:

```toml fp=pyproject.toml
[tool.coverage.paths]
source = ["src", "*/site-packages"]

[tool.coverage.run]
branch = true
source = ["hypermodern_python"]

[tool.coverage.report]
show_missing = true
```

To enable coverage reporting:

```shell
poetry run pytest --cov
```

You can configure Coverage.py to require full test coverage (or any other target
percentage) using the `fail_under` option:

```toml fp=pyproject.toml
[tool.coverage.report]
fail_under = 100
```

### Test automation with Nox

Nox is a successor to the venerable tox. At its core, the tool automates testing
in multiple Python environments. Nox makes it easy to run any kind of job in an
isolated environment, with only those dependencies installed that the job needs.

```shell
pip install --user --upgrade nox
```

Unlike tox, Nox uses a standard Python file for configuration:

```python nu fp=noxfile.py
import nox

@nox.session(python=["3.8", "3.7"])
def tests(session):
    session.run("poetry", "install", external=True)
    session.run("pytest", "--cov")
```

This file defines a session named `tests`, which installs the project
dependencies and runs the test suite. Poetry is not a part of the environment
created by Nox, so we specify `external` to avoid warnings about external
commands leaking into the isolated test environments.

Nox creates virtual environments for the listed Python versions (3.8 and 3.7),
and runs the session inside each environment:

```shell
nox
```

Nox recreates the virtual environments from scratch on each invocation (a
sensible default). You can speed things up by passing the
`--reuse-existing-virtualenvs` (`-r`) option:

```shell
nox -r
```

Change the session to allow overriding the options passed to `pytest`:

```python nu fp=noxfile.py hl=5
import nox

@nox.session(python=["3.8", "3.7"])
def tests(session):
    args = session.posargs or ["--cov"]
    session.run("poetry", "install", external=True)
    session.run("pytest", *args)
```

```shell
nox -- tests/test_console.py
```

### Mocking with pytest-mock

Unit tests should be fast, isolated, and repeatable. The test for `console.main`
is neither of these:

- It is not fast, because it takes a full round-trip to the Wikipedia API to
  complete.
- It does not run in an isolated environment, because it sends out an actual
  request over the network.
- It is not repeatable, because its outcome depends on the health, reachability,
  and behavior of the API. In particular, the test fails whenever the network is
  down.

The `unittest.mock` standard library allows you to replace parts of your system
under test with mock objects. Use it via the `pytest-mock` plugin, which
integrates the library with `pytest`:

```shell
poetry add --dev pytest-mock
```

The plugin provides a `mocker` fixture, which functions as a thin wrapper around
the standard mocking library. Use `mocker.patch` to replace the `requests.get`
function by a mock object. The mock object will be useful for any test case
involving the Wikipedia API, so let’s create a test fixture for it:

```python fp=tests/test_console.py
@pytest.fixture
def mock_requests_get(mocker):
    return mocker.patch("requests.get")

def test_main_succeeds(runner, mock_requests_get):
    ...
```

If you run Nox now, the test fails because click expects to be passed a string
for console output, and receives a mock object instead. Simply “knocking out”
`requests.get` is not quite enough. The mock object also needs to return
something meaningful, namely a response with a valid JSON object.

When a mock object is called, or when an attribute is accessed, it returns
another mock object. Sometimes this is sufficient to get you through a test
case. When it is not, you need to _configure_ the mock object. To configure an
attribute, you simply set the attribute to the desired value. To configure the
return value for when the mock is called, you set `return_value` on the mock
object as if it were an attribute.

```python
with requests.get(API_URL) as response:
    response.raise_for_status()
    data = response.json()
```

The code above uses the response as a context manager. The `with` statement is
syntactic sugar for the following slightly simplified pseudocode:

```python
context = requests.get(API_URL)
response = context.__enter__()

try:
    response.raise_for_status()
    data = response.json()
finally:
    context.__exit__(...)
```

So what you have is essentially a chain of function calls:

```python
data = requests.get(API_URL).__enter__().json()
```

Rewrite the fixture, and mirror this call chain when you configure the mock:

```python fp=tests/test_console.py hl=4..7
@pytest.fixture
def mock_requests_get(mocker):
    mock = mocker.patch("requests.get")
    mock.return_value.__enter__.return_value.json.return_value = {
        "title": "Lorem Ipsum",
        "extract": "Lorem ipsum dolor sit amet",
    }
    return mock
```

```python fp=tests/test_console.py
def test_main_prints_title(runner, mock_requests_get):
    result = runner.invoke(console.main)
    assert "Lorem Ipsum" in result.output
```

Additionally, mocks can be inspected to see if they were called, using the
mock’s `called` attribute. This provides you with a way to check that
`requests.get` was invoked to send a request to the API:

```python fp=tests/test_console.py
def test_main_invokes_requests_get(runner, mock_requests_get):
    runner.invoke(console.main)
    assert mock_requests_get.called
```

Mock objects also allow you to inspect the arguments they were called with,
using the `call_args` attribute. This allows you to check the URL passed to
`requests.get`:

```python fp=tests/test_console.py
def test_main_uses_en_wikipedia_org(runner, mock_requests_get):
    runner.invoke(console.main)
    args, _ = mock_requests_get.call_args
    assert "en.wikipedia.org" in args[0]
```

You can configure a mock to raise an exception instead of returning a value by
assigning the exception instance or class to the `side_effect` attribute of the
mock. Let’s check that the program exits with a status code of 1 on request
errors:

```python fp=tests/test_console.py
def test_main_fails_on_request_error(runner, mock_requests_get):
    mock_requests_get.side_effect = Exception("Boom")
    result = runner.invoke(console.main)
    assert result.exit_code == 1
```

Tests for a feature or bugfix should be written _before_ implementation. This is
also known as “writing a failing test". The reason for this is that it provides
confidence that the tests are actually testing something, and do not simply pass
because of a flaw in the tests themselves.

### Example CLI: Refactoring

Let’s move the Wikipedia client to a separate module. Create a file
`src/hypermodern-python/wikipedia.py` with the following contents:

```python nu fp=src/hypermodern_python/wikipedia.py
import requests

API_URL = "https://en.wikipedia.org/api/rest_v1/page/random/summary"

def random_page():
    with requests.get(API_URL) as response:
        response.raise_for_status()
        return response.json()
```

The `console` module can now simply invoke `wikipedia.random_page`:

```python nu fp=src/hypermodern_python/console.py hl=11
import textwrap

import click

from . import __version__, wikipedia

@click.command()
@click.version_option(version=__version__)
def main():
    """The hypermodern Python project."""
    data = wikipedia.random_page()

    title = data["title"]
    extract = data["extract"]

    click.secho(title, fg="green")
    click.echo(textwrap.fill(extract))
```

### Example CLI: Handling exceptions gracefully

If you run the example application without an Internet connection, your terminal
will be filled with a long traceback. This is what happens when the Python
interpreter is terminated by an unhandled exception. For common errors such as
this, it would be better to print a friendly, informative message to the screen.

Let’s express this as a test case, by configuring the mock to raise a
`RequestException`. (The `requests` library has more specific exception classes,
but for the purposes of this example, we will only deal with the base class.)

```python fp=tests/test_console.py
import requests

def test_main_prints_message_on_request_error(runner, mock_requests_get):
    mock_requests_get.side_effect = requests.RequestException
    result = runner.invoke(console.main)
    assert "Error" in result.output
```

The simplest way to get this test to pass is by converting the
`RequestException` into a `ClickException`. When click encounters this
exception, it prints the exception message to standard error and exits the
program with a status code of 1. You can reuse the exception message by
converting the original exception to a string.

```python nu fp=src/hypermodern_python/wikipedia.py hl=1,7,11..13
import click
import requests

API_URL = "https://en.wikipedia.org/api/rest_v1/page/random/summary"

def random_page():
    try:
        with requests.get(API_URL) as response:
            response.raise_for_status()
            return response.json()
    except requests.RequestException as error:
        message = str(error)
        raise click.ClickException(message)
```

### Example CLI: Selecting the Wikipedia language edition

```python fp=tests/test_wikipedia.py
from hypermodern_python import wikipedia

def test_random_page_uses_given_language(mock_requests_get):
    wikipedia.random_page(language="de")
    args, _ = mock_requests_get.call_args
    assert "de.wikipedia.org" in args[0]
```

The `mock_requests_get` fixture is now used by two test modules. You could move
it to a separate module and import from there, but Pytest offers a more
convenient way: Fixtures placed in a `conftest.py` file are discovered
automatically, and test modules at the same directory level can use them without
explicit import. Create the new file at the top-level of your tests package, and
move the fixture there:

```python nu fp=tests/conftest.py
import pytest

@pytest.fixture
def mock_requests_get(mocker):
    mock = mocker.patch("requests.get")
    mock.return_value.__enter__.return_value.json.return_value = {
        "title": "Lorem Ipsum",
        "extract": "Lorem ipsum dolor sit amet",
    }
    return mock
```

```python nu fp=src/hypermodern-python/wikipedia.py hl=4,6..7,9
import click
import requests

API_URL = "https://{language}.wikipedia.org/api/rest_v1/page/random/summary"

def random_page(language="en"):
    url = API_URL.format(language=language)
    try:
        with requests.get(url) as response:
            response.raise_for_status()
            return response.json()
    except requests.RequestException as error:
        message = str(error)
        raise click.ClickException(message)
```

As the second step, we make the new functionality accessible from the command
line, adding a `--language` option. The test case mocks the
`wikipedia.random_page` function, and uses the `assert_called_with` method on
the mock to check that the language specified by the user is passed on to the
function:

```python fp=tests/test_console.py
@pytest.fixture
def mock_wikipedia_random_page(mocker):
    return mocker.patch("hypermodern_python.wikipedia.random_page")

def test_main_uses_specified_language(runner, mock_wikipedia_random_page):
    runner.invoke(console.main, ["--language=pl"])
    mock_wikipedia_random_page.assert_called_with(language="pl")
```

```python nu fp=src/hypermodern-python/console.py hl=8..15,17,19
import textwrap

import click

from . import __version__, wikipedia

@click.command()
@click.option(
    "--language",
    "-l",
    default="en",
    help="Language edition of Wikipedia",
    metavar="LANG",
    show_default=True,
)
@click.version_option(version=__version__)
def main(language):
    """The hypermodern Python project."""
    data = wikipedia.random_page(language=language)

    title = data["title"]
    extract = data["extract"]

    click.secho(title, fg="green")
    click.echo(textwrap.fill(extract))
```

### Using fakes

Mocks help you test code units depending on bulky subsystems, but they are not
the only technique to do so. For example, if your function requires a database
connection, it may be both easier and more effective to pass an in-memory
database than a mock object. Fake implementations are a good alternative to mock
objects, which can be too forgiving when faced with wrong usage, and too tightly
coupled to implementation details of the system under test (witness the
`mock_requests_get` fixture). Large data objects can be generated by test object
factories, instead of being replaced by mock objects (check out the excellent
`factoryboy` package).

Suppose you have written the following fake API implementation:

```python
class FakeAPI:
    url = "http://localhost:5000/"

    @classmethod
    def create(cls):
        ...

    def shutdown(self):
        ...
```

The following will not work:

```python
@pytest.fixture
def fake_api():
    return FakeAPI.create()
```

The API needs to be shut down after use, to free up resources such as the TCP
port and the thread running the server. You can do this by writing the fixture
as a generator:

```python
@pytest.fixture
def fake_api():
    api = FakeAPI.create()
    yield api
    api.shutdown()
```

Pytest takes care of running the generator, passing the yielded value to your
test function, and executing the shutdown code after it returns. If setting up
and tearing down the fixture is expensive, you may also consider extending the
scope of the fixture. By default, fixtures are created once per test function.
Instead, you could create the fake API server once per test session:

```python
@pytest.fixture(scope="session")
def fake_api():
    api = FakeAPI.create()
    yield api
    api.shutdown()
```

### End-to-end testing

Testing against the live production server is bad practice for unit tests, but
there is nothing like the confidence you get from seeing your code work in a
real environment. Such tests are known as _end-to-end_ tests, and while they are
usually too slow, brittle, and unpredictable for the kind of automated testing
you would want to do on a CI server or in the midst of development, they do have
their place.

Use Pytest’s markers to apply a custom mark. This will allow you to select or
skip them later, using Pytest’s `-m` option.

```python fp=tests/test_console.py
@pytest.mark.e2e
def test_main_succeeds_in_production_env(runner):
    result = runner.invoke(console.main)
    assert result.exit_code == 0
```

Register the `e2e` marker using the `pytest_configure` hook, as shown below. The
hook is placed in the `conftest.py` file, at the top-level of your tests
package. This ensures that Pytest can discover the module and use it for the
entire test suite.

```python fp=tests/conftest.py
def pytest_configure(config):
    config.addinivalue_line("markers", "e2e: mark as end-to-end test.")
```

Finally, exclude end-to-end tests from automated testing by passing
`-m "not e2e"` to Pytest:

```python nu fp=noxfile.py hl=5
import nox

@nox.session(python=["3.8", "3.7"])
def tests(session):
    args = session.posargs or ["--cov", "-m", "not e2e"]
    session.run("poetry", "install", external=True)
    session.run("pytest", *args)
```

```shell
nox -rs tests-3.8 -- -m e2e
```

## Linting

### Linting with Flake8

Linters analyze source code to flag programming errors, bugs, stylistic errors,
and suspicious constructs. The most common ones for Python are pylint and the
linter aggregators flake8, pylama, and prospector. There are also multi-language
linter frameworks such as pre-commit and coala.

```python fp=noxfile.py
locations = "src", "tests", "noxfile.py"

@nox.session(python=["3.8", "3.7"])
def lint(session):
    args = session.posargs or locations
    session.install("flake8")
    session.run("flake8", *args)
```

Flake8 glues together several tools. The messages produced by these tools are
assigned error codes, prefixed by one or more letters. The prefixes group the
errors into so-called violation classes:

- `F` are errors reported by pyflakes, a tool which parses source files and
  finds invalid Python code.
- `W` and `E` are warnings and errors reported by pycodestyle, which checks your
  Python code against some of the style conventions in PEP 8.
- `C` are violations reported by mccabe, which checks the code complexity of
  your Python package against a configured limit.

Configure Flake8 using the `.flake8` configuration file, enabling all the
built-in violation classes and setting the complexity limit:

```toml nu fp=.flake8
[flake8]
select = C,E,F,W
max-complexity = 10
```

By default, Nox runs all sessions defined in `noxfile.py`. Use the `--session`
(`-s`) option to restrict it to a specific session:

```shell
nox -rs lint
```

### Code formatting with Black

The next addition to our toolbox is Black, the uncompromising Python code
formatter. One of its greatest features is its lack of configurability.
Blackened code looks the same regardless of the project you’re reading.

```python fp=noxfile.py
@nox.session(python="3.8")
def black(session):
    args = session.posargs or locations
    session.install("black")
    session.run("black", *args)
```

Invoking `nox` without arguments triggers all the sessions, including Black. It
would be better to only validate the coding style without modifying the
conflicting files. Exclude Black from the sessions run by default, by setting
`nox.options.sessions` at the top:

```python fp=noxfile.py
nox.options.sessions = "lint", "tests"
```

Instead, check adherence to the Black code style inside the linter session. The
`flake8-black` plugin generates warnings if it detects that Black would reformat
a source file:

```python fp=noxfile.py hl=4
@nox.session(python=["3.8", "3.7"])
def lint(session):
    args = session.posargs or locations
    session.install("flake8", "flake8-black")
    session.run("flake8", *args)
```

Configure Flake8 to enable the `flake8-black` warnings, which are prefixed by
`BLK`. Also, some built-in warnings do not align well with Black. You need to
ignore warnings `E203` (Whitespace before ‘:'), and `W503` (Line break before
binary operator), and set the maximum line length to a more permissive value:

```toml fp=.flake8
[flake8]
select = BLK,C,E,F,W
ignore = E203,W503
max-line-length = 88
```

### Checking imports with flake8-import-order

The flake8-import-order plugin checks that import statements are grouped and
ordered in a consistent and PEP 8-compliant way.

```python fp=noxfile.py hl=4
@nox.session(python=["3.8", "3.7"])
def lint(session):
    args = session.posargs or locations
    session.install("flake8", "flake8-black", "flake8-import-order")
    session.run("flake8", *args)
```

Enable the warnings emitted by the plugin (`I` like _import_).

```toml fp=.flake8
[flake8]
select = BLK,C,E,F,I,W
```

Inform the plugin about package names which are considered local:

```toml fp=.flake8
[flake8]
application-import-names = hypermodern_python,tests
```

Adopt the Google styleguide with respect to the grouping and ordering details:

```toml fp=.flake8
[flake8]
import-order-style = google
```

### Finding more bugs with flake8-bugbear

The `flake8-bugbear` plugin helps you find various bugs and design problems in
your programs.

```python fp=noxfile.py hl=4
@nox.session(python=["3.8", "3.7"])
def lint(session):
    args = session.posargs or locations
    session.install("flake8", "flake8-black", "flake8-bugbear", "flake8-import-order")
    session.run("flake8", *args)
```

Enable the plugin warnings in Flake8’s configuration file (`B` like _bugbear_):

```toml fp=.flake8
[flake8]
select = B,B9,BLK,C,E,F,I,W
```

`B9` is required for Bugbear’s more opinionated warnings, which are disabled by
default. In particular, `B950` checks the maximum line length like the built-in
`E501`, but with a tolerance margin of 10%. Ignore the built-in error `E501` and
set the maximum line length to a sane value:

```toml fp=.flake8
[flake8]
ignore = E203,E501,W503
max-line-length = 80
```

### Identifying security issues with Bandit

Bandit is a tool designed to find common security issues in Python code.

```python fp=noxfile.py hl=6
@nox.session(python=["3.8", "3.7"])
def lint(session):
    args = session.posargs or locations
    session.install(
        "flake8",
        "flake8-bandit",
        "flake8-black",
        "flake8-bugbear",
        "flake8-import-order",
    )
    session.run("flake8", *args)
```

Enable the plugin warnings in Flake8’s configuration file (`S` like _security_):

```toml fp=.flake8
[flake8]
select = B,B9,BLK,C,E,F,I,S,W
...
```

Bandit flags uses of `assert` to enforce interface constraints because
assertions are removed when compiling to optimized byte code. You should disable
this warning for your test suite, as Pytest uses assertions to verify
expectations in tests:

```toml fp=.flake8
[flake8]
per-file-ignores = tests/*:S101
...
```

Bandit finds known issues that can be detected via static file checking. If you
are very concerned with security, you should consider using additional tools,
for example a fuzzing tool such as python-afl.

### Finding security vulnerabilities in dependencies with Safety

Safety checks the dependencies of your project for known security
vulnerabilities, using a curated database of insecure Python packages.

```python fp=noxfile.py
import tempfile

@nox.session(python="3.8")
def safety(session):
    with tempfile.NamedTemporaryFile() as requirements:
        session.run(
            "poetry",
            "export",
            "--dev",
            "--format=requirements.txt",
            "--without-hashes",
            f"--output={requirements.name}",
            external=True,
        )
        session.install("safety")
        session.run("safety", "check", f"--file={requirements.name}", "--full-report")
```

The session uses the poetry export command to convert Poetry’s lock file to a
requirements file, for consumption by Safety. The standard tempfile module is
used to create a temporary file for the requirements.

```python fp=noxfile.py
nox.options.sessions = "lint", "safety", "tests"
```

```shell
poetry add insecure-package
nox -rs safety
poetry remove insecure-package
```

### Managing dependencies in Nox sessions with Poetry

```python fp=noxfile.py
def install_with_constraints(session, *args, **kwargs):
    with tempfile.NamedTemporaryFile() as requirements:
        session.run(
            "poetry",
            "export",
            "--dev",
            "--format=requirements.txt",
            f"--output={requirements.name}",
            external=True,
        )
        session.install(f"--constraint={requirements.name}", *args, **kwargs)
```

```python fp=noxfile.py nu hl=4,11..18,34
@nox.session(python="3.8")
def black(session):
    args = session.posargs or locations
    install_with_constraints(session, "black")
    session.run("black", *args)


@nox.session(python=["3.8", "3.7"])
def lint(session):
    args = session.posargs or locations
    install_with_constraints(
        session,
        "flake8",
        "flake8-bandit",
        "flake8-black",
        "flake8-bugbear",
        "flake8-import-order",
    )
    session.run("flake8", *args)


@nox.session(python="3.8")
def safety(session):
    with tempfile.NamedTemporaryFile() as requirements:
        session.run(
            "poetry",
            "export",
            "--dev",
            "--format=requirements.txt",
            "--without-hashes",
            f"--output={requirements.name}",
            external=True,
        )
        install_with_constraints(session, "safety")
        session.run("safety", "check", f"--file={requirements.name}", "--full-report")
```

```shell
poetry add --dev \
    black \
    flake8 \
    flake8-bandit \
    flake8-black \
    flake8-bugbear \
    flake8-import-order \
    safety
```

```python fp=noxfile.py nu
@nox.session(python=["3.9", "3.8"])
def tests(session):
    args = session.posargs or ["--cov", "-m", "not e2e"]
    session.run("poetry", "install", "--no-dev", external=True)
    install_with_constraints(
        session, "coverage[toml]", "pytest", "pytest-cov", "pytest-mock"
    )
    session.run("pytest", *args)
```

### Managing Git hooks with pre-commit

Git provides hooks which allow you to run custom commands when important actions
occur, such as a commit or push. You can leverage this to run automated checks
when you commit changes. pre-commit is a framework for managing and maintaining
such hooks. Use it to integrate the best industry standard linters into your
workflow, even those written in a language other than Python.

```shell
pip install --user --upgrade pre-commit
```

```yaml nu fp=.pre-commit-config.yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v2.3.0
    hooks:
      - id: check-yaml
      - id: end-of-file-fixer
      - id: trailing-whitespace
  - repo: https://github.com/psf/black
    rev: 19.3b0
    hooks:
      - id: black
```

Install the hooks by running the following command:

```shell
pre-commit install
```

The hooks run automatically every time you invoke `git commit`, applying checks
to any newly created or modified files. When you add new hooks, you can trigger
them manually for all files using the following command:

```shell
pre-commit run --all-files
```

```yaml nu fp=.pre-commit-config.yaml hl=10..19
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v2.3.0
    hooks:
      - id: check-yaml
      - id: end-of-file-fixer
      - id: trailing-whitespace
  - repo: local
    hooks:
      - id: black
        name: black
        entry: poetry run black
        language: system
        types: [python]
      - id: flake8
        name: flake8
        entry: poetry run flake8
        language: system
        types: [python]
```

## Typing

### Type annotations and type checkers

Type annotations are a way to annotate functions and variables with types.
Combined with tooling that understands them, they can make your programs easier
to understand, debug, and maintain.

A static type checker can use type annotations and type inference to verify the
type correctness of your program without executing it, helping you discover many
bugs that would otherwise go unnoticed.

### Static type checking with mypy

```shell
poetry add --dev mypy
```

```python fp=noxfile.py
nox.options.sessions = "lint", "mypy", "tests"

...

@nox.session(python=["3.8", "3.7"])
def mypy(session):
    args = session.posargs or locations
    install_with_constraints(session, "mypy")
    session.run("mypy", *args)
```

Mypy raises an error if it cannot find any type definitions for a Python package
used by your program. Unless you are going to write these type definitions
yourself, you should disable the error using the `mypy.ini` configuration file:

```ini nu fp=mypy.ini
[mypy]

[mypy-nox.*,pytest]
ignore_missing_imports = True
```

Specifying the packages explicitly helps you keep track of dependencies that are
currently out of scope of the type checker. You may soon be able to cut down on
this list, as many projects are actively working on typing support.

### Static type checking with pytype

```shell
poetry add --dev pytype
```

```python fp=noxfile.py
nox.options.sessions = "lint", "mypy", "pytype", "tests"

...

@nox.session(python="3.7")
def pytype(session):
    """Run the static type checker."""
    args = session.posargs or ["--disable=import-error", *locations]
    install_with_constraints(session, "pytype")
    session.run("pytype", *args)
```

In this session, we use the command-line option `--disable=import-error` because
pytype, like mypy, reports import errors for third-party packages without type
annotations.

### Adding type annotations to the package

```python fp=src/hypermodern_python/console.py
def main(language: str) -> None: ...
```

```python fp=src/hypermodern_python/wikipedia.py
from typing import Any

API_URL: str = "https://{language}.wikipedia.org/api/rest_v1/page/random/summary"

def random_page(language: str = "en") -> Any: ...
```

### Data validation using Desert and Marshmallow

Returning `Any` is unsatisfactory, because we know quite precisely which JSON
structures we can expect from the Wikipedia API. An API contract is not a type
guarantee, but you can turn it into one by validating the data you receive. This
will also demonstrate some great ways to use type annotations _at runtime_.

The first step is to define the target type for the validation. Currently, the
function should return a dictionary with several keys, of which we are only
interested in title and extract. But your program can do better than operating
on a dictionary: Using dataclasses from the standard library, you can define a
fully-featured data type in a concise and straightforward manner. Let’s define a
`wikipedia.Page` type for our application:

```python fp=src/hypermodern_python/wikipedia.py
from dataclasses import dataclass

...

@dataclass
class Page:
    title: str
    extract: str

def random_page(language: str = "en") -> Page: ...
```

```python fp=src/hypermodern_python/console.py hl=5..6
def main(language: str) -> None:
    """The hypermodern Python project."""
    page = wikipedia.random_page(language=language)

    click.secho(page.title, fg="green")
    click.echo(textwrap.fill(page.extract))
```

```python fp=tests/test_wikipedia.py
def test_random_page_returns_page(mock_requests_get):
    page = wikipedia.random_page()
    assert isinstance(page, wikipedia.Page)
```

Marshmallow allows you to define schemas to serialize, deserialize and validate
data. Used by countless applications, Marshmallow has also spawned anecosystem
of tools and libraries built on top of it. One of these libraries,Desert, uses
the type annotations of dataclasses to generate serialization schemasfor them.
(Another great data validation library using type annotations is typical)

```shell
poetry add desert marshmallow
```

```ini fp=mypy.ini
[mypy-desert,marshmallow,nox.*,pytest]
ignore_missing_imports = True
```

Our data type represents the Wikipedia page resource only partially. Marshmallow
errs on the side of safety and raises a validation error when encountering
unknown fields. However, you can tell it to ignore unknown fields via the `meta`
keyword. Add the schema as a module-level variable:

```python nu fp=src/hypermodern_python/wikipedia.py hl=1..2,6,8,15,16
import desert
import marshmallow

...

schema = desert.schema(Page, meta={"unknown": marshmallow.EXCLUDE})

def random_page(language: str = "en") -> Page:
    url = API_URL.format(language=language)

    try:
        with requests.get(url) as response:
            response.raise_for_status()
            data = response.json()
            return schema.load(data)
    except (requests.RequestException, marshmallow.ValidationError) as error:
        message = str(error)
        raise click.ClickException(message)
```

```python fp=tests/test_wikipedia.py
def test_random_page_handles_validation_errors(mock_requests_get):
    mock_requests_get.return_value.__enter__.return_value.json.return_value = None
    with pytest.raises(click.ClickException):
        wikipedia.random_page()
```

### Runtime type checking with Typeguard

Typeguard is a runtime type checker for Python: It checks that arguments match
parameter types of annotated functions as your program is being executed (and
similarly for return values). Runtime type checking can be a valuable tool when
it is impossible or impractical to strictly type an entire code path, for
example when crossing system boundaries or interfacing with other libraries.

```shell
poetry add --dev typeguard
```

Typeguard comes with a Pytest plugin which instruments your package for type
checking while you run the test suite. You can enable it by passing the
`--typeguard-packages` option with the name of your package. Add a Nox session
to run the test suite with runtime type checking:

```python fp=noxfile.py
package = "hypermodern_python"

@nox.session(python=["3.8", "3.7"])
def typeguard(session):
    args = session.posargs or ["-m", "not e2e"]
    session.run("poetry", "install", "--no-dev", external=True)
    install_with_constraints(session, "pytest", "pytest-mock", "typeguard")
    session.run("pytest", f"--typeguard-packages={package}", *args)
```

Typeguard catches the bug we introduced at the start of this section. You will
also notice a warning about missing type annotations for a Click object. This is
due to the fact that `console.main` is wrapped by a decorator, and its type
annotations only apply to the inner function, not the resulting object as seen
by the test suite.

### Increasing type coverage with flake8-annotations

`flake8-annotations` is a Flake8 plugin that detects the absence of type
annotations for functions, helping you keep track of unannotated code.

```shell
poetry add --dev flake8-annotations
```

```python fp=noxfile.py hl=7
@nox.session(python=["3.8", "3.7"])
def lint(session):
    args = session.posargs or locations
    install_with_constraints(
        session,
        "flake8",
        "flake8-annotations",
        "flake8-bandit",
        "flake8-black",
        "flake8-bugbear",
        "flake8-import-order",
    )
    session.run("flake8", *args)
```

Configure Flake8 to switch on the warnings generated by the plugin (`ANN` like
_annotations_):

```ini fp=.flake8
[flake8]
select = ANN,B,B9,BLK,C,E,F,I,S,W
```

The plugin spews out a multitude of warnings about missing type annotations in
the Nox sessions and the test suite. It is possible to disable warnings for
these locations using Flake8’s `per-file-ignores` option:

```ini fp=.flake8
[flake8]
per-file-ignores =
    tests/*:S101,ANN
    noxfile.py:ANN
```

### Adding type annotations to Nox sessions

```python fp=noxfile.py
from nox.sessions import Session

def install_with_constraints(session: Session, *args: str, **kwargs: Any) -> None: ...

def black(session: Session) -> None: ...

def lint(session: Session) -> None: ...

def safety(session: Session) -> None: ...

def mypy(session: Session) -> None: ...

def pytype(session: Session) -> None: ...

def tests(session: Session) -> None: ...

def typeguard(session: Session) -> None: ...
```

### Adding type annotations to the test suite

The `mock_requests_get` fixture returns a standard mock object of type
`unittest.mock.Mock`.

```python fp=tests/test_wikipedia.py
from unittest.mock import Mock

def test_random_page_uses_given_language(mock_requests_get: Mock) -> None: ...

def test_random_page_returns_page(mock_requests_get: Mock) -> None: ...

def test_random_page_handles_validation_errors(mock_requests_get: Mock) -> None: ...
```

```python fp=tests/conftest.py
from unittest.mock import Mock

from _pytest.config import Config
from pytest_mock import MockFixture

def pytest_configure(config: Config) -> None: ...

def mock_requests_get(mocker: MockFixture) -> Mock: ...
```

```ini fp=mypy.ini
[mypy-desert,marshmallow,nox.*,pytest,pytest_mock,_pytest.*]
ignore_missing_imports = True
```

```python fp=tests/test_console.py
from unittest.mock import Mock

from click.testing import CliRunner
from pytest_mock import MockFixture

def runner() -> CliRunner: ...

def mock_wikipedia_random_page(mocker: MockFixture) -> Mock: ...

def test_main_succeeds(runner: CliRunner, mock_requests_get: Mock) -> None: ...

def test_main_succeeds_in_production_env(runner: CliRunner) -> None: ...

def test_main_prints_title(runner: CliRunner, mock_requests_get: Mock) -> None: ...

def test_main_invokes_requests_get(runner: CliRunner, mock_requests_get: Mock) -> None: ...

def test_main_uses_en_wikipedia_org(runner: CliRunner, mock_requests_get: Mock) -> None: ...

def test_main_uses_specified_language(runner: CliRunner, mock_wikipedia_random_page: Mock) -> None: ...

def test_main_fails_on_request_error(runner: CliRunner, mock_requests_get: Mock) -> None: ...

def test_main_prints_message_on_request_error(runner: CliRunner, mock_requests_get: Mock) -> None: ...
```

## Documentation

### Documenting code with Python docstrings

```python fp=src/hypermodern_python/console.py
def main(language: str) -> None:
    """The hypermodern Python project."""
```

Documentation strings communicate the purpose and usage of a module, class, or
function to other developers reading your code. Unlike comments, the Python
bytecode compiler does not throw them away, but adds them to the `__doc__`
attribute of documented objects. This allows tools like Sphinx to generate API
documentation from your code.

You can document your entire package by adding a docstring to the top of
`__init__.py`:

```python fp=src/hypermodern_python/__init__.py
"""The hypermodern Python project."""
```

Document the modules in your package by adding docstrings to the top of their
respective source files.

```python fp=src/hypermodern_python/console.py
"""Command-line interface."""
```

```python fp=src/hypermodern_python/wikipedia.py
"""Client for the Wikipedia REST API, version 1."""
```

So far we have used one-line docstrings. Docstrings can also consist of multiple
lines. By convention, the first line is separated from the rest of the docstring
by a blank line. This structures the docstring into a summary line and a more
elaborate description.

Docstring summaries can include useful information about class attributes,
function parameters, return values, and other things. A common format for this
with good readability and tooling support is the Google docstring style. Other
options are the Sphinx and NumPy formats.

```python fp=src/hypermodern_python/wikipedia.py
@dataclass
class Page:
    """Page resource.

    Attributes:
        title: The title of the Wikipedia page.
        extract: A plain text summary.
    """

def random_page(language: str = "en") -> Page:
    """Return a random page.

    Performs a GET request to the /page/random/summary endpoint.

    Args:
        language: The Wikipedia language edition. By default, the English
            Wikipedia is used ("en").

    Returns:
        A page resource.

    Raises:
        ClickException: The HTTP request failed or the HTTP response
            contained an invalid body.
    """
```

### Linting code documentation with flake8-docstrings

The flake8-docstrings plugin uses the tool pydocstyle to check that docstrings
are compliant with the style recommendations of PEP 257. Warnings range from
missing docstrings to issues with whitespace, quoting, and docstring content.

```shell
poetry add --dev flake8-docstrings
```

```python fp=noxfile.py hl=11
@nox.session(python=["3.8", "3.7"])
def lint(session: Session) -> None:
    args = session.posargs or locations
    install_with_constraints(
        session,
        "flake8",
        "flake8-annotations",
        "flake8-bandit",
        "flake8-black",
        "flake8-bugbear",
        "flake8-docstrings",
        "flake8-import-order",
    )
    session.run("flake8", *args)
```

Configure Flake8 to enable the plugin warnings (`D` for docstring) and adopt the
Google docstring style:

```ini fp=.flake8
select = ANN,B,B9,BLK,C,D,E,F,I,S,W
docstring-convention = google
```

### Adding docstrings to Nox sessions

Docstrings in Nox sessions make your noxfile.py a friendly, welcoming place for
contributors (as well as for yourself a few months down the road). This is
especially true since Nox shows them when you list the sessions using
`--list-sessions`.

```python fp=noxfile.py
"""Nox sessions."""

def install_with_constraints(session: Session, *args: str, **kwargs: Any) -> None:
    """Install packages constrained by Poetry's lock file."""

def black(session: Session) -> None:
    """Run black code formatter."""

def lint(session: Session) -> None:
    """Lint using flake8."""

def safety(session: Session) -> None:
    """Scan dependencies for insecure packages."""

def mypy(session: Session) -> None:
    """Type-check using mypy."""

def pytype(session: Session) -> None:
    """Type-check using pytype."""

def tests(session: Session) -> None:
    """Run the test suite."""

def typeguard(session: Session) -> None:
    """Runtime type checking using Typeguard."""
```

```shell
nox --list-sessions
```

### Adding docstrings to the test suite

Docstrings for test cases are a great way to improve the readability of your
test suite. They help you keep test function names succinct without becoming
obscure, and they can be used to make test output more friendly.

```python nu fp=tests/__init__.py
"""Test suite for the hypermodern_python package."""
```

```python fp=tests/conftest.py
"""Package-wide test fixtures."""

def pytest_configure(config: Config) -> None:
    """Pytest configuration hook."""

def mock_requests_get(mocker: MockFixture) -> Mock:
    """Fixture for mocking requests.get."""
```

```python fp=tests/test_console.py
"""Test cases for the console module."""

def runner() -> CliRunner:
    """Fixture for invoking command-line interfaces."""

def mock_wikipedia_random_page(mocker: MockFixture) -> Mock:
    """Fixture for mocking wikipedia.random_page."""

def test_main_succeeds(runner: CliRunner, mock_requests_get: Mock) -> None:
    """It exits with a status code of zero."""

def test_main_succeeds_in_production_env(runner: CliRunner) -> None:
    """It exits with a status code of zero (end-to-end)."""

def test_main_prints_title(runner: CliRunner, mock_requests_get: Mock) -> None:
    """It prints the title of the Wikipedia page."""

def test_main_invokes_requests_get(runner: CliRunner, mock_requests_get: Mock) -> None:
    """It invokes requests.get."""

def test_main_uses_en_wikipedia_org(runner: CliRunner, mock_requests_get: Mock) -> None:
    """It uses the English Wikipedia by default."""

def test_main_uses_specified_language(runner: CliRunner, mock_wikipedia_random_page: Mock) -> None:
    """It uses the specified language edition of Wikipedia."""

def test_main_fails_on_request_error(runner: CliRunner, mock_requests_get: Mock) -> None:
    """It exits with a non-zero status code if the request fails."""

def test_main_prints_message_on_request_error(runner: CliRunner, mock_requests_get: Mock) -> None:
    """It prints an error message if the request fails."""
```

```python fp=tests/test_wikipedia.py
"""Test cases for the wikipedia module."""

def test_random_page_uses_given_language(mock_requests_get: Mock) -> None:
    """It selects the specified Wikipedia language edition."""

def test_random_page_returns_page(mock_requests_get: Mock) -> None:
    """It returns an object of type Page."""

def test_random_page_handles_validation_errors(mock_requests_get: Mock) -> None:
    """It raises `ClickException` when validation fails."""
```

### Validating docstrings against function signatures with darglint

Darglint checks that docstring descriptions match function definitions, and
integrates with Flake8 as a plugin.

```shell
poetry add --dev darglint
```

Unlike other plugins, darglint enables most of its warnings by default. For
consistency and to future-proof your Flake8 configuration, enable the plugin
warnings explicitly (`DAR` like _darglint_):

```ini fp=.flake8
[flake8]
select = ANN,B,B9,BLK,C,D,DAR,E,F,I,S,W
```

```python fp=noxfile.py hl=14
@nox.session(python=["3.8", "3.7"])
def lint(session: Session) -> None:
    """Lint using flake8."""
    args = session.posargs or locations
    install_with_constraints(
        session,
        "flake8",
        "flake8-annotations",
        "flake8-bandit",
        "flake8-black",
        "flake8-bugbear",
        "flake8-docstrings",
        "flake8-import-order",
        "darglint",
    )
    session.run("flake8", *args)
```

By default, Darglint requires every docstring to completely specify parameters,
return value, and exceptions. In some cases, this is not desirable. For example,
documenting the parameters of test functions or Nox sessions would mostly create
redundancy. Configure darglint to accept one-line docstrings, using the
.darglint configuration file:

```ini nu fp=.darglint
[darglint]
strictness = short
```

### Running documentation examples with xdoctest

A good way to explain how to use your function or module is to include an
example in its docstring. By convention, docstring examples are written as if
entered at a Python prompt.

```python fp=src/hypermodern_python/wikipedia.py hl=17..21
def random_page(language: str = "en") -> Page:
    """Return a random page.

    Performs a GET request to the /page/random/summary endpoint.

    Args:
        language: The Wikipedia language edition. By default, the English
            Wikipedia is used ("en").

    Returns:
        A page resource.

    Raises:
        ClickException: The HTTP request failed or the HTTP response
            contained an invalid body.

    Example:
        >>> from hypermodern_python import wikipedia
        >>> page = wikipedia.random_page(language="en")
        >>> bool(page.title)
        True
    """
```

The xdoctest package runs the examples in your docstrings and compares the
actual output to the expected output as per the docstring. This serves multiple
purposes:

- The example is checked for correctness.
- You ensure that the documentation is up-to-date.
- Your codebase gets additional test coverage for free.

```shell
poetry add --dev xdoctest
```

```python fp=noxfile.py
@nox.session(python=["3.8", "3.7"])
def xdoctest(session: Session) -> None:
    """Run examples with xdoctest."""
    args = session.posargs or ["all"]
    session.run("poetry", "install", "--no-dev", external=True)
    install_with_constraints(session, "xdoctest")
    session.run("python", "-m", "xdoctest", package, *args)
```

By default, the Nox session uses the `all` subcommand to run all examples. You
can also `list` the examples using the list subcommand, or run specific
examples:

```shell
nox -rs xdoctest -- random_page
```

Xdoctest integrates with Pytest as a plugin, so you could also install the tool
into your existing Nox session for Pytest, and enable it via the `--xdoctest`
option. We are using it in stand-alone mode here, which has the advantage of
keeping unit tests and doctest separate.

### Creating documentation with Sphinx

Sphinx is the documentation tool used by the official Python documentation and
many open-source projects.

```shell
poetry add --dev sphinx
```

Create a directory `docs`. The master document is located in the file
`docs/index.rst`. Let’s start with a simple placeholder text:

```rest fp=docs/index.rst
This is docs/index.rst,
documenting the Hypermodern Python project.
```

```python fp=docs/conf.py
"""Sphinx configuration."""
project = "hypermodern-python"
author = "Your Name"
copyright = f"2020, {author}"
```

Add a Nox session to build the documentation:

```python fp=noxfile.py
locations = "src", "tests", "noxfile.py", "docs/conf.py"

@nox.session(python="3.8")
def docs(session: Session) -> None:
    """Build the documentation."""
    install_with_constraints(session, "sphinx")
    session.run("sphinx-build", "docs", "docs/_build")
```

```shell
nox -rs docs
```

You can now open the file `docs/_build/index.html` in your browser to view your
documentation offline.

### Writing documentation using reStructuredText

Sphinx documentation is commonly written using reStructuredText (reST), although
Markdown is also supported. reStructuredText may not be as lightweight as
Markdown, but its expressiveness and extensibility, among other reasons, make it
more suitable for writing technical documentation.

```rest nu fp=docs/index.rst
The Hypermodern Python Project
==============================

The example project for the
`Hypermodern Python <https://medium.com/@cjolowicz/hypermodern-python-d44485d9d769>`_
article series.
The command-line interface prints random facts to your console,
using the `Wikipedia API <https://en.wikipedia.org/api/rest_v1/#/>`_.


Installation
------------

To install the Hypermodern Python project,
run this command in your terminal:

.. code-block:: console

   $ pip install hypermodern-python


Usage
-----

Hypermodern Python's usage looks like:

.. code-block:: console

   $ hypermodern-python [OPTIONS]

.. option:: -l <language>, --language <language>

   The Wikipedia language edition,
   as identified by its subdomain on
   `wikipedia.org <https://www.wikipedia.org/>`_.
   By default, the English Wikipedia is selected.

.. option:: --version

   Display the version and exit.

.. option:: --help

   Display a short usage message and exit.
```

Indentation is significant, like in Python. Three spaces are customary, because
they line up directives with their content.

Directives like `code-block` are Sphinx extensions, but unlike the fenced code
blocks of GitHub Flavored Markdown, they use a standard extension mechanism
built into the base language. While reStructuredText provides some directives of
its own, Sphinx defines many more, creating an expressive semantic markup
language that lets you focus on meaning instead of formatting.

Sphinx documentation can be spread over multiple interconnected files. Let’s see
how this works by including the license in the documentation. Create a file
`docs/license.rst`, which includes the `LICENSE` file from the parent directory
using an include directive:

```rest nu fp=docs/license.rst
License
=======

.. include:: ../LICENSE
```

Add the license to the navigation sidebar by adding a `toctree` directive to the
main document in `docs/index.rst`.

```rest fp=docs/index.rst
The Hypermodern Python Project
==============================

.. toctree::
   :hidden:
   :maxdepth: 1

   license
```

The `:hidden:` option prevents the table of contents from being inserted into
the main document itself, which makes sense since it is already included in the
sidebar. The `:maxdepth: 1` option turns the navigation sidebar into a flat
list, instead of a nested hierarchy including the internal structure of each
documentation page.

### Generating API documentation with autodoc

We use Sphinx to generate API documentation from the documentation strings and
type annotations in the package, using three Sphinx extensions:

- `autodoc` enables Sphinx to generate API documentation from the docstrings in
  your package.
- `napoleon` pre-processes Google-style docstrings to reStructuredText.
- `sphinx-autodoc-typehints` uses type annotations to document the types of
  function parameters and return values.

The autodoc and napoleon extensions are distributed with Sphinx, so there is no
need to install them explicitly.

```shell
poetry add --dev sphinx-autodoc-typehints
```

```python fp=noxfile.py hl=4..5
@nox.session(python="3.8")
def docs(session: Session) -> None:
    """Build the documentation."""
    session.run("poetry", "install", "--no-dev", external=True)
    install_with_constraints(session, "sphinx", "sphinx-autodoc-typehints")
    session.run("sphinx-build", "docs", "docs/_build")
```

```python nu fp=docs/conf.py hl=4..8
project = "hypermodern-python"
author = "Your Name"
copyright = f"2020, {author}"
extensions = [
    "sphinx.ext.autodoc",
    "sphinx.ext.napoleon",
    "sphinx_autodoc_typehints",
]
```

You can now reference docstrings in your Sphinx documentation using directives
such as `automodule`, `autoclass`, and `autofunction`.

Create the file `docs/reference.rst`, containing the API reference for the
project:

```rest nu fp=docs/reference.rst
Reference
=========

.. contents::
    :local:
    :backlinks: none


hypermodern_python.console
--------------------------

.. automodule:: hypermodern_python.console
   :members:


hypermodern_python.wikipedia
----------------------------

.. automodule:: hypermodern_python.wikipedia
   :members:
```

The `automodule` directive inserts the documentation for the specified Python
module. With the `:members:` option, it also includes documentation for the
classes and functions defined by the module.

The contents directive inserts a table of content into the document. The
`:local:` option avoids including the page title in the table of contents. The
`:backlinks:` none option avoids linking each section title to the table of
contents.

Include the new file in the navigation sidebar, by updating the `toctree`
directive at the top of `docs/index.rst`:

```rest fp=docs/index.rst hl=9
The Hypermodern Python Project
==============================

.. toctree::
   :hidden:
   :maxdepth: 1

   license
   reference
```

## CI/CD

### Continuous integration using GitHub Actions

_Continuous integration_ (CI) helps you automate the integration of code changes
into your project. When changes are pushed to the project repository, the CI
server verifies their correctness, triggering tools such as unit tests, linters,
or type checkers.

Pull Requests are an important building block in this workflow. They let you
propose a set of changes to the repository, for example a specific bugfix or new
feature. When the pull request gets accepted, its changes are merged into the
target branch, typically master. GitHub displays Pull Requests with a green tick
if they pass CI, and with a red x if the CI pipeline failed. In this way,
continuous integration functions as a gate commits need to pass to enter the
master branch.

Configure GitHub Actions by adding the following YAML file to the
`.github/workflows` directory:

```yaml nu fp=.github/workflows/tests.yml
name: Tests
on: push
jobs:
  tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v1
        with:
          python-version: 3.8
          architecture: x64
      - run: pip install nox==2019.11.9
      - run: pip install poetry==1.0.5
      - run: nox
```

This file defines a so-called _workflow_. A workflow is an automated process
executing a series of steps, grouped into one or many jobs. Workflows are
triggered by events, for example when someone pushes a commit to a repository,
or when someone creates a pull request, an issue, or a release.

The workflow above is triggered on every push to your GitHub repository, and
executes the test suite using Nox. It is aptly named “Tests”, and consists of a
single job running on the latest supported Ubuntu image. The job executes five
steps, using either official GitHub Actions or invoking shell commands:

1. Check out your repository using `actions/checkout`.
2. Install Python 3.8 using `actions/setup-python`.
3. Install Nox with pip.
4. Install Poetry with pip.
5. Run your test suite with Nox.

Every tool used in the CI process is pinned to a specific version. The reasoning
behind this is that a CI process should be predictable and deterministic. There
is a common fallacy that you should always use the latest version of a specific
tool, and therefore that tool should not be pinned.

By all means, use the latest versions of your tools, but be explicit about it.
This gives your project a higher level of auditability, and prevents things from
magically breaking and un-breaking in CI. Upgrading tools in a dedicated pull
request also lets you investigate the impact of an upgrade, rather than breaking
your entire CI when a new version becomes available.

The workflow currently uses Python 3.8 only, but you should really test your
project on all Python versions it supports. You can achieve this using a _build
matrix_. A build matrix lets you define variables, such as for the operating
system or for the Python version, and specify multiple values for them. Jobs can
reference these variables, and are instantiated for every combination of values.

Let’s define a build matrix for the Python versions supported by the project
(Python 3.7 and 3.8). Use the `strategy` and `matrix` keywords to define a build
matrix with a `python-version` variable, and reference the variable using the
syntax `${{ matrix.python-version }}`:

```yaml nu fp=.github/workflows/tests.yml hl=6..9,14
name: Tests
on: push
jobs:
  tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.7", "3.8"]
    name: Python ${{ matrix.python-version }}
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v1
        with:
          python-version: ${{ matrix.python-version }}
          architecture: x64
      - run: pip install nox==2019.11.9
      - run: pip install poetry==1.0.5
      - run: nox
```

If you commit and push now, you can watch the workflow execute under the

<Scr>Actions</Scr> tab in your GitHub repository, with a separate job for each Python
version.

You should also add a GitHub Actions badge to your repository page. The badge
indicates whether the tests are passing or failing on the master branch, and
links to the GitHub Actions dashboard for your project.

Add the line below to the top of your `README.md` to display the badge:

```markdown fp=README.md
[![Tests](https://github.com/<your-username>/hypermodern-python/workflows/Tests/badge.svg)](https://github.com/<your-username>/hypermodern-python/actions?workflow=Tests)
```

### Coverage reporting with Codecov

A coverage reporting service offers some additional benefits, by making code
coverage more visible:

- Pull requests get automated comments with a quick rundown of how the changes
  affect coverage.
- The site visualizes code coverage for every commit and file in your
  repository, using graphs and code listings.
- You can display code coverage on your repository page, using a badge.

We use Codecov for coverage reporting. Sign up at Codecov, install their GitHub
app, and add your repository to Codecov. The sign up process will guide you
through these steps.

Add the official codecov CLI to your development dependencies:

```shell
poetry add --dev codecov
```

Add the Nox session shown below. The session exports the coverage data to
cobertura XML format, which is the format expected by Codecov. It then uses
`codecov` to upload the coverage data.

```python fp=noxfile.py
@nox.session(python="3.8")
def coverage(session: Session) -> None:
    """Upload coverage data."""
    install_with_constraints(session, "coverage[toml]", "codecov")
    session.run("coverage", "xml", "--fail-under=0")
    session.run("codecov", *session.posargs)
```

Note that you need to disable the coverage minimum using the command-line option
`--fail-under=0`. Otherwise, you would only get coverage reports when coverage
is at 100%, defeating their very purpose.

Next, grant GitHub Actions access to upload to Codecov:

1. Go to your repository settings on Codecov, and copy the <Scr>Repository
   Upload Token</Scr>.
2. Go to your repository settings on GitHub, and add a secret named
   `CODECOV_TOKEN` with the token you just copied.

Add the following GitHub workflow to upload coverage data:

```yaml nu fp=.github/workflows/coverage.yml
name: Coverage
on: push
jobs:
  coverage:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v1
        with:
          python-version: "3.8"
          architecture: x64
      - run: pip install nox==2019.11.9
      - run: pip install poetry==1.0.5
      - run: nox --sessions tests-3.8 coverage
        env:
          CODECOV_TOKEN: ${{secrets.CODECOV_TOKEN}}
```

In contrast to the Tests workflow, the Coverage workflow only runs on Python
3.8. It invokes Nox to execute the test suite and upload the coverage data,
providing the Codecov token as an environment variable.

Add the Codecov badge to your `README.md`:

```markdown fp=README.md
[![Codecov](https://codecov.io/gh/<your-username>/hypermodern-python/branch/master/graph/badge.svg)](https://codecov.io/gh/<your-username>/hypermodern-python)
```

### Uploading your package to PyPI

Before you can upload your Python package, you need to generate distribution
packages. These are compressed archives which an end-user can download and
install on their system. They come in two flavours: source (or _sdist_)
archives, and binary packages in the wheel format. Poetry supports generating
both with the `poetry build` command:

```shell
poetry build
```

Poetry also supports uploading your package to PyPI, with the `poetry publish`
command:

```shell
poetry publish
```

Automation helps you ensure your Python package passes all checks before it is
published, and keeps the build and upload process itself reliable.

Sign up at PyPI, and enable two-factor authentication for an additional layer of
security. Next, grant GitHub Actions permission to upload to PyPI:

1. Go to the <Scr>Account settings</Scr> on PyPI, generate an API token, and
   copy it.
2. Go to the repository settings on GitHub, and add a secret named `PYPI_TOKEN`
   with the token you just copied.

The following GitHub workflow uploads your package to PyPI when you release it:

```yaml fp=.github/workflows/release.yml
name: Release
on:
  release:
    types: [published]
jobs:
  release:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v1
        with:
          python-version: "3.8"
          architecture: x64
      - run: pip install nox==2019.11.9
      - run: pip install poetry==1.0.5
      - run: nox
      - run: poetry build
      - run:
          poetry publish --username=__token__ --password=${{ secrets.PYPI_TOKEN
          }}
```

The release workflow is triggered when you publish a GitHub Release. GitHub
Releases are based on Git tags, which mark a specific point in your repository’s
history. Here’s how you can create and publish a release for your project:

1. Go to the Releases tab of your main repository page.
2. Click <Scr>Create a new release</Scr>.
3. Enter the Git tag. By convention, these tags have the form `v<version>`.
4. Enter the title and description for your release.
5. Click <Scr>Publish release</Scr>.

The release workflow should now start building your package, and upload the
resulting artifacts to PyPI. At the start of the workflow, the test suite is run
once more to ensure that the package passes all checks.

Add a badge to `README.md` which links to your PyPI project page and displays
the latest release:

```markdown fp=README.md
[![PyPI](https://img.shields.io/pypi/v/hypermodern-python.svg)](https://pypi.org/project/hypermodern-python/)
```

### Documenting releases with Release Drafter

The Release Drafter action drafts your next release notes as pull requests are
merged into master. It does this by creating and maintaining a draft release.
When a pull request gets accepted, the release description is updated to include
its title, author, and a link to the pull request itself.

When you’re ready to make a release, you simply need to add the tag name, and
click _Publish_. You’re also free to edit the release description further, for
example to include a more general description of the release.

Add the following workflow to use Release Drafter:

```yaml nu fp=.github/workflows/release-drafter.yml
name: Release Drafter
on:
  push:
    branches:
      - master
jobs:
  draft_release:
    runs-on: ubuntu-latest
    steps:
      - uses: release-drafter/release-drafter@v5.6.1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

Another useful feature of Release Drafter is to group pull requests based on
labels you apply to them. This would allow you, for example, to have separate
headings for features, bugfixes, and documentation in the release notes, using
GitHub’s _enhancement_, _bug_, and _documentation_ labels.

The configuration file below goes somewhat further, and is very loosely based on
the Angular Commit Message Convention and gitmoji. You will need to add the
remaining labels to your repository manually, using New Label on the Issues tab
of the repository.

```yaml nu fp=.github/release-drafter.yml
categories:
  - title: ":boom: Breaking Changes"
    label: "breaking"
  - title: ":package: Build System"
    label: "build"
  - title: ":construction_worker: Continuous Integration"
    label: "ci"
  - title: ":books: Documentation"
    label: "documentation"
  - title: ":rocket: Features"
    label: "enhancement"
  - title: ":beetle: Fixes"
    label: "bug"
  - title: ":racehorse: Performance"
    label: "performance"
  - title: ":hammer: Refactoring"
    label: "refactoring"
  - title: ":fire: Removals and Deprecations"
    label: "removal"
  - title: ":lipstick: Style"
    label: "style"
  - title: ":rotating_light: Testing"
    label: "testing"
template: |
  ## What’s Changed

  $CHANGES
```

### Single-sourcing the package version

Before creating the next release of your package, you need to bump the version
of your package. Use `poetry version` to update the version declared in
`pyproject.toml`:

```shell
poetry version <version>
```

You can pass the new version explicitly, or a rule such as `major`, `minor`, or
`patch`. In a nutshell, increment the major version if the release contains
breaking changes, the patch level if the release contains only bugfixes, and the
minor version in all other cases. This assumes that your project has a stable
and public API, and a version number greater than or equal to `1.0.0`. For more
details, refer to the Semantic Versioning standard.

As it stands, you also need to update the version declared inside your package’s
`__init__.py`. We can streamline this process even further, by determining the
version automatically using the installed package metadata. This is possible in
Python 3.8 using the standard `importlib.metadata` library, and in Python 3.7
and earlier using its backport `importlib_metadata`.

```shell
poetry add --python="<3.8" importlib_metadata
```

Determining the package version should really be as simple as the following:

```python nu fp=src/hypermodern_python/__init__.py
"""The hypermodern Python project."""

from importlib.metadata import version


__version__ = version(__name__)
```

However, the actual implementation is slightly more complicated, due to the fact
that the import path depends on the Python version, and the possibility that the
package has not been installed (although this should rarely happen, thanks to
src layout). For the same reasons, we need to disable type checking and coverage
for certain lines.

```python nu fp=src/hypermodern_python/__init__.py
"""The hypermodern Python project."""

try:
    from importlib.metadata import version, PackageNotFoundError  # type: ignore
except ImportError:  # pragma: no cover
    from importlib_metadata import version, PackageNotFoundError  # type: ignore


try:
    __version__ = version(__name__)
except PackageNotFoundError:  # pragma: no cover
    __version__ = "unknown"
```

With this in place, `pyproject.toml` has become the single source of truth for
your package version.

### Uploading your package to TestPyPI

TestPyPI is a separate instance of the Python Package Index that allows you to
try distribution tools and processes without affecting the real index.

Sign up at TestPyPI, and grant GitHub Actions permission to upload to TestPyPI:

1. Go to the <Scr>Account settings</Scr> on TestPyPI, generate an API token, and
   copy it.
2. Go to the repository settings on GitHub, and add a secret named
   `TEST_PYPI_TOKEN` with the token you just copied.

The following GitHub workflow builds and uploads your package to TestPyPI from
the master branch of your repository:

```yaml nu fp=.github/workflows/test-pypi.yml
name: TestPyPI
on:
  push:
    branches:
      - master
jobs:
  test_pypi:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v1
        with:
          python-version: "3.8"
          architecture: x64
      - run: pip install poetry==1.0.5
      - run: >-
          poetry version patch && version=$(poetry version | awk '{print $2}')
          && poetry version $version.dev.$(date +%s)
      - run: poetry build
      - uses: pypa/gh-action-pypi-publish@v1.0.0a0
        with:
          user: __token__
          password: ${{ secrets.TEST_PYPI_TOKEN }}
          repository_url: https://test.pypi.org/legacy/
```

TestPyPI does not allow you to overwrite an existing package version. The
workflow therefore bumps the version and appends a suffix of the form
`.dev.<timestamp>`, indicating a developmental release. The package is then
built and uploaded using the PyPI publish GitHub Action of the Python Packaging
Authority.

### Hosting documentation at Read the Docs

Read the Docs hosts documentation for countless open-source Python projects. The
hosting service also takes care of rebuilding the documentation when you update
your project. Users can browse documentation for every published version, as
well as the latest development version.

Create the `.readthedocs.yml` configuration file:

```yaml nu =.readthedocs.yml
version: 2
sphinx:
  configuration: docs/conf.py
formats: all
python:
  version: 3.7
  install:
    - requirements: docs/requirements.txt
    - path: .
```

The `install` section in the configuration file tells Read the Docs how to
install your package and its documentation dependencies. Read the Docs does not
support installation of dependencies using Poetry directly. Luckily, pip can
install any package with a standard `pyproject.toml` file, and will use
`poetry-core` behind the scenes.

On the other hand, the development dependencies on Sphinx and its extensions are
not declared in the package. (And even if they were, dependencies declared in
the package are not pinned, so we might run into problems due to slightly
different build environments.) Uploading the documentation from a GitHub
workflow would solve this nicely, but this is currently not supported. So let’s
be pragmatic and duplicate the documentation dependencies using a separate
requirements file:

```txt nu fp=docs/requirements.txt
sphinx==2.3.1
sphinx-autodoc-typehints==1.10.3
```

Sign up at Read the Docs, and import your GitHub repository, using the button
Import a Project. Read the Docs automatically starts building your
documentation. When the build has completed, your documentation will have a
public URL like this: https://hypermodern-python.readthedocs.io/.

You can display the documentation link on PyPI by including it in your package
configuration file:

```toml fp=pyproject.toml
[tool.poetry]
documentation = "https://hypermodern-python.readthedocs.io"
```

Let’s also add the link to the GitHub repository page, by adding a Read the Docs
badge to `README.md`:

```markdown fp=README.md
[![Read the Docs](https://readthedocs.org/projects/hypermodern-python/badge/)](https://hypermodern-python.readthedocs.io/)
```
