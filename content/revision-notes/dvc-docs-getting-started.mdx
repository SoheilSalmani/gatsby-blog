---
title: Get Started
resourceId: https://dvc.org/doc/start
stoppedAt: Data and Model Versioning
---

```shell
pip install dvc
```

Depending on the type of the remote storage you plan to use, you might need to
install optional dependencies: `[s3]`, `[azure]`, `[gdrive]`, `[gs]`, `[oss]`,
`[ssh]`. Use `[all]` to include them all.

Initialize DVC by running `dvc init` inside a Git project:

```shell
dvc init
```

DVC's features can be grouped into functional components:

- **Data and model versioning** is the base layer of DVC for large files,
  datasets, and machine learning models. Use a regular Git workflow, but without
  storing large files in the repo (think "Git for data"). Data is stored
  separately, which allows for efficient sharing.
- **Data and model access** shows how to use data artifacts from outside of the
  project and how to import data artifacts from another DVC project. This can
  help to download a specific version of an ML model to a deployment server or
  import a model to another project.
- **Data pipelines** describe how models and other data artifacts are built, and
  provide an efficient way to reproduce them. Think "Makefiles for data and ML
  projects" done right.
- **Metrics, parameters, and plots** can be attached to pipelines. These let you
  capture, navigate, and evaluate ML projects without leaving Git. Think "Git
  for machine learning".
- **Experiments** enable exploration, iteration, and comparison across many ML
  experiments. Track your experiments with automatic versioning and checkpoint
  logging. Compare differences in parameters, metrics, code, and data. Apply,
  drop, roll back, resume, or share any experiment.

Once you set up your DVC repository, you can also interact with it using DVC
Studio, the online UI for DVC.

## Data and Model Versioning

## Data and Model Access

## Data Pipelines

## Metrics, Parameters, and Plots

## Experiments
